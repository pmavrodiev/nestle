{
  "paragraphs": [
    {
      "text": "%spark\n\nimport org.apache.spark._\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n/* spark context is in \u0027sc \u0027 */\n\n/* Create a Hive context for interaction with Hive via HiveQL */\n//var hiveContext \u003d new org.apache.spark.sql.hive.HiveContext(sc)\n\nvar sparkConf \u003d sc.getConf.getAll\n",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 8:44:00 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478688594580_-949696631",
      "id": "20161109-114954_1956231180",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark._\n\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\nsparkConf: Array[(String, String)] \u003d Array((spark.history.kerberos.keytab,none), (spark.eventLog.enabled,true), (master,yarn-client), (zeppelin.spark.concurrentSQL,false), (spark.yarn.containerLauncherMaxThreads,25), (spark.driver.extraLibraryPath,/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64), (spark.driver.host,10.38.228.200), (spark.executorEnv.PYTHONPATH,/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip:/usr/hdp/current/spark-client/python/:/usr/hdp/current/spark-client/python:/usr/hdp/current/spark-client/python/lib/py4j-0.8.2.1-src.zip\u003cCPS\u003e{{PWD}}/pyspark.zip\u003cCPS\u003e{{PWD}}/py4j-0.9-src.zip), (spark.executor.extraLibraryPath,/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64),..."
      },
      "dateCreated": "Nov 9, 2016 11:49:54 AM",
      "dateStarted": "Nov 10, 2016 8:44:00 AM",
      "dateFinished": "Nov 10, 2016 8:44:00 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Define vertex types",
      "text": "%spark\n\n/* Define the different types of vertices */\nclass VertexProperty(val propertyName: String, val id: Int) extends Serializable // base class\ncase class ReadNode(val name: String, val read_id: Int) extends VertexProperty(name, read_id) \ncase class ContigNode(val name: String, val contig_id: Int, val organism_id: Int) extends VertexProperty(name, contig_id) \ncase class OrganismNode(val name: String, val organism_id: Int) extends VertexProperty(name, organism_id) \n",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 11:30:55 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478688611909_862116588",
      "id": "20161109-115011_894699029",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ndefined class VertexProperty\n\ndefined class ReadNode\n\ndefined class ContigNode\n\ndefined class OrganismNode\n"
      },
      "dateCreated": "Nov 9, 2016 11:50:11 AM",
      "dateStarted": "Nov 10, 2016 11:30:55 AM",
      "dateFinished": "Nov 10, 2016 11:30:55 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Define edge types",
      "text": "%spark\n\nclass EdgeBase(val _type: String) extends Serializable // base calss\n\n/*** read-to-contig edge between a ReadNode and a ContigNode ***/\n/*\n    pos:\n        The start position at which the read was matched to the contig\n    count:\n        The number of characters matched counting from the starting position\n    quality:\n        The quality of the match. DEFAULT \u003d 0\n    conf:\n        The confidence of the match. To be computed after the whole graph is contructed. \n        Every edge is created with default confidence of 1.0. DEFAULT \u003d 1.0\n*/\n\ncase class RCedge(pos: Int, count: Int \u003d 20, \n                  quality: Double \u003d 0.0, conf: Double \u003d 1.0) extends EdgeBase(\"RCedge\")\n\n/*** read-to-read edge between 2 nodes of type ReadNode ***/\n/*\n    contig_node_id: \n        The node_id of the contig to which the 2 nodes (reads) are mapped\n    weight: \n        The closeness between the 2 nodes.  Can be quantified as a function of the positions to which the nodes map onto\n        the contig. For example: 1 / abs(pos2 - pos1)\n*/\ncase class RRedge(contig_node_id: Long, weight: Double) extends EdgeBase(\"RRedge\")\n\n/*** contig-to-organism edge between a contig and an organism***/\n/* the mapping between contig and organism must be injective */\ncase class COedge(edge_id: Int) extends EdgeBase(\"COedge\")\n\n               \n\n\n\n\n",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 11:55:01 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478699382624_-535018651",
      "id": "20161109-144942_1588913755",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ndefined class EdgeBase\n\ndefined class RCedge\n\ndefined class RRedge\n\ndefined class COedge\n"
      },
      "dateCreated": "Nov 9, 2016 2:49:42 PM",
      "dateStarted": "Nov 10, 2016 11:55:01 AM",
      "dateFinished": "Nov 10, 2016 11:55:01 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initialize the nodes",
      "text": "%spark\nnodes match {\n    case _: RDD[_] \u003d\u003e nodes.unpersist() \n}\n\nval nodes: RDD[(Long, VertexProperty)] \u003d \n    sc.parallelize(Array((0L,  ReadNode(name \u003d \"read\", read_id \u003d 1)),\n                         (1L,  ReadNode(name \u003d \"read\", read_id \u003d 2)),\n                         (2L,  ReadNode(name \u003d \"read\", read_id \u003d 3)),\n                         (3L,  ReadNode(name \u003d \"read\", read_id \u003d 4)),\n                         (4L,  ReadNode(name \u003d \"read\", read_id \u003d 5)),\n                         (5L,  ReadNode(name \u003d \"read\", read_id \u003d 6)),\n                         (6L,  ReadNode(name \u003d \"read\", read_id \u003d 7)),\n                         (7L,  ContigNode(name \u003d \"contig\", contig_id \u003d 1, organism_id \u003d 1)),\n                         (8L,  ContigNode(name \u003d \"contig\", contig_id \u003d 2, organism_id \u003d 2)),\n                         (9L,  ContigNode(name \u003d \"contig\", contig_id \u003d 3, organism_id \u003d 2)),\n                         (10L, ContigNode(name \u003d \"contig\", contig_id \u003d 4, organism_id \u003d 3)),\n                         (11L, OrganismNode(name \u003d \"organism\", organism_id \u003d 1)),\n                         (12L, OrganismNode(name \u003d \"organism\", organism_id \u003d 2)),\n                         (13L, OrganismNode(name \u003d \"organism\", organism_id \u003d 3))\n    ))",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 11:33:57 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478690821287_1809356868",
      "id": "20161109-122701_929294798",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nres136: nodes.type \u003d ParallelCollectionRDD[94] at parallelize at \u003cconsole\u003e:58\n\nnodes: org.apache.spark.rdd.RDD[(Long, VertexProperty)] \u003d ParallelCollectionRDD[96] at parallelize at \u003cconsole\u003e:58\n"
      },
      "dateCreated": "Nov 9, 2016 12:27:01 PM",
      "dateStarted": "Nov 10, 2016 11:33:57 AM",
      "dateFinished": "Nov 10, 2016 11:33:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initialize the edges",
      "text": "%spark\nedges match {\n    case _: RDD[_] \u003d\u003e edges.unpersist() \n}\n\nval edges: RDD[Edge[EdgeBase]]\u003d \n    sc.parallelize(Array(\n            /* contig-to-organism (CO) edges */\n             Edge(7L, 11L, COedge(edge_id \u003d 0).asInstanceOf[EdgeBase]),\n             Edge(8L, 12L, COedge(edge_id \u003d 1).asInstanceOf[EdgeBase]),\n             Edge(9L, 12L, COedge(edge_id \u003d 2).asInstanceOf[EdgeBase]),\n             Edge(10L, 13L,COedge(edge_id \u003d 3).asInstanceOf[EdgeBase]),\n            /* read-to-contig (RC) edges */\n             Edge(0L, 8L,  RCedge(pos \u003d 0).asInstanceOf[EdgeBase]),\n             Edge(1L, 8L,  RCedge(pos \u003d 1).asInstanceOf[EdgeBase]),\n             Edge(2L, 8L,  RCedge(pos \u003d 2).asInstanceOf[EdgeBase]),\n             Edge(2L, 7L,  RCedge(pos \u003d 2).asInstanceOf[EdgeBase]),\n             Edge(2L, 10L, RCedge(pos \u003d 2).asInstanceOf[EdgeBase]),\n             Edge(3L, 8L,  RCedge(pos \u003d 3).asInstanceOf[EdgeBase]),\n             Edge(3L, 9L,  RCedge(pos \u003d 3).asInstanceOf[EdgeBase]),\n             Edge(3L, 10L, RCedge(pos \u003d 4).asInstanceOf[EdgeBase]),\n             Edge(4L, 8L,  RCedge(pos \u003d 4).asInstanceOf[EdgeBase]),\n             Edge(5L, 8L,  RCedge(pos \u003d 5).asInstanceOf[EdgeBase]),\n             Edge(6L, 8L,  RCedge(pos \u003d 6).asInstanceOf[EdgeBase])\n    ))",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 11:33:49 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478701018132_-1305140929",
      "id": "20161109-151658_1077425242",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nres135: edges.type \u003d ParallelCollectionRDD[88] at parallelize at \u003cconsole\u003e:52\n\nedges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[EdgeBase]] \u003d ParallelCollectionRDD[95] at parallelize at \u003cconsole\u003e:56\n"
      },
      "dateCreated": "Nov 9, 2016 3:16:58 PM",
      "dateStarted": "Nov 10, 2016 11:33:49 AM",
      "dateFinished": "Nov 10, 2016 11:33:49 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n\n\n// create a paired RDD\n//(Edge(0,8,RCedge(0,20,0.0,1.0)),Edge(0,8,RCedge(0,20,0.0,1.0)))\ndef constructRRedge(edge1: Edge[RCedge], edge2: Edge[RCedge]): Edge[EdgeBase] \u003d {\n    val dest_1 \u003d edge1.dstId\n    val dest_2 \u003d edge2.dstId\n    if ( dest_1 \u003d\u003d dest_2 ) {\n        // the two Reads have been mapped to the same Contig -\u003e create RRedge\n        val src_1 \u003d edge1.srcId\n        val src_2 \u003d edge2.srcId\n        val pos_1 \u003d edge1.attr.pos\n        val pos_2 \u003d edge2.attr.pos\n        val weight \u003d Math.abs(pos_1 - pos_2)\n        Edge(src_1, src_2, RRedge(contig_node_id \u003d dest_1, weight \u003d weight).asInstanceOf[EdgeBase])\n    }\n    else Edge(-1, -1, new EdgeBase(\"none\"))\n}\n",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 12:01:03 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478716015377_-890466900",
      "id": "20161109-192655_51737905",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nconstructRRedge: (edge1: org.apache.spark.graphx.Edge[RCedge], edge2: org.apache.spark.graphx.Edge[RCedge])org.apache.spark.graphx.Edge[EdgeBase]\n"
      },
      "dateCreated": "Nov 9, 2016 7:26:55 PM",
      "dateStarted": "Nov 10, 2016 12:01:03 PM",
      "dateFinished": "Nov 10, 2016 12:01:03 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nRC_edges match {\n    case _: RDD[_] \u003d\u003e RC_edges.unpersist()\n}\n\n\nval RC_edges \u003d edges\n                .filter(e \u003d\u003e (e.attr).isInstanceOf[RCedge])\n\nval RR_edges \u003d RC_edges\n                .cartesian(RC_edges) // (Edge(0,8,RCedge(0,20,0.0,1.0)),Edge(1,8,RCedge(1,20,0.0,1.0)))\n                .map(x \u003d\u003e constructRRedge(x._1, x._2)) //Edge(0,8,RCedge(0,20,0.0,1.0)), Edge(1,8,RCedge(1,20,0.0,1.0))\n                \n//RC_edges.cartesian(RC_edges).collect().foreach(m \u003d\u003e println(m))\n\n\n//edges.cartesian(edges).collect().foreach(println(_))\n\n/*\nval edges_paired \u003d edges\n                    .filter(e \u003d\u003e (e.attr)._type \u003d\u003d \"RCedge\") // Edge(4,8,EdgeType[.type\u003d\u003d\"RCedge\"]), Edge(5,8,EdgeType[.type\u003d\u003d\"RCedge\"])\n                    .map(e \u003d\u003e (e.dstId, e)) // 8 -\u003e Edge(4,8,EdgeType[.type\u003d\u003d\"RCedge\"]), 8 -\u003e Edge(5,8,EdgeType[.type\u003d\u003d\"RCedge\"])\n  \n  \n  */                  \n\n\n\n\n",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 12:00:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478710911923_-1540614800",
      "id": "20161109-180151_2009481780",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "\nres207: RC_edges.type \u003d MapPartitionsRDD[150] at filter at \u003cconsole\u003e:58\n\n\n\n\n\n\n\u003cconsole\u003e:61: error: reference to RCedge is ambiguous;\nit is imported twice in the same scope by\nimport INSTANCE.RCedge\nand import INSTANCE.RCedge\n                       .filter(e \u003d\u003e (e.attr).isInstanceOf[RCedge])\n                                                          ^\n"
      },
      "dateCreated": "Nov 9, 2016 6:01:51 PM",
      "dateStarted": "Nov 10, 2016 12:00:19 PM",
      "dateFinished": "Nov 10, 2016 12:00:19 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\naccum.value",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 10:59:09 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478771921307_783044454",
      "id": "20161110-105841_652206731",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nres110: Int \u003d 7\n"
      },
      "dateCreated": "Nov 10, 2016 10:58:41 AM",
      "dateStarted": "Nov 10, 2016 10:59:09 AM",
      "dateFinished": "Nov 10, 2016 10:59:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initialize the graph",
      "text": "%spark\n\nval graph \u003d Graph(nodes, edges)\n",
      "user": "admin",
      "dateUpdated": "Nov 9, 2016 5:09:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478702098542_-923518758",
      "id": "20161109-153458_231906083",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ngraph: org.apache.spark.graphx.Graph[VertexProperty,EdgeProperty] \u003d org.apache.spark.graphx.impl.GraphImpl@10796181\n"
      },
      "dateCreated": "Nov 9, 2016 3:34:58 PM",
      "dateStarted": "Nov 9, 2016 5:09:43 PM",
      "dateFinished": "Nov 9, 2016 5:09:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n\n/*\n\nval facts: RDD[String] \u003d \n    graph.triplets.map(triplet \u003d\u003e triplet.srcAttr.propertyName + \" \" + triplet.srcAttr.id + \" -\u003e \" + triplet.dstAttr.propertyName + \" \" + triplet.dstAttr.id + \" \" + triplet.attr)\nval bubu \u003d facts.collect().foreach(println(_))\n\n*/\n\nval read_to_contigs \u003d graph.edges.filter(e \u003d\u003e (e.attr).isInstanceOf[RCedge])\nread_to_contigs.collect()\n\n\n",
      "user": "admin",
      "dateUpdated": "Nov 9, 2016 5:14:04 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478702620082_-557302391",
      "id": "20161109-154340_1088538662",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nread_to_contigs: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[EdgeProperty]] \u003d MapPartitionsRDD[637] at filter at \u003cconsole\u003e:67\n\nres68: Array[org.apache.spark.graphx.Edge[EdgeProperty]] \u003d Array(Edge(0,8,RCedge(0,20,0.0,1.0)), Edge(1,8,RCedge(1,20,0.0,1.0)), Edge(2,8,RCedge(2,20,0.0,1.0)), Edge(2,7,RCedge(2,20,0.0,1.0)), Edge(2,10,RCedge(2,20,0.0,1.0)), Edge(3,8,RCedge(3,20,0.0,1.0)), Edge(3,9,RCedge(3,20,0.0,1.0)), Edge(3,10,RCedge(4,20,0.0,1.0)), Edge(4,8,RCedge(4,20,0.0,1.0)), Edge(5,8,RCedge(5,20,0.0,1.0)), Edge(6,8,RCedge(6,20,0.0,1.0)))\n"
      },
      "dateCreated": "Nov 9, 2016 3:43:40 PM",
      "dateStarted": "Nov 9, 2016 5:14:04 PM",
      "dateFinished": "Nov 9, 2016 5:14:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n\nvar x \u003d edges.take(1)\nx(0).attr\n",
      "user": "admin",
      "dateUpdated": "Nov 10, 2016 9:31:33 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478707599713_-1598711515",
      "id": "20161109-170639_163072442",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nx: Array[org.apache.spark.graphx.Edge[EdgeProperty]] \u003d Array(Edge(7,11,COedge(0)))\n\nres67: EdgeProperty \u003d COedge(0)\n"
      },
      "dateCreated": "Nov 9, 2016 5:06:39 PM",
      "dateStarted": "Nov 10, 2016 9:31:33 AM",
      "dateFinished": "Nov 10, 2016 9:31:33 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n",
      "dateUpdated": "Nov 10, 2016 9:05:16 AM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1478765116449_281218115",
      "id": "20161110-090516_281113335",
      "dateCreated": "Nov 10, 2016 9:05:16 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "pavlin-Spark",
  "id": "2C3DAA6KY",
  "angularObjects": {
    "2C2FVSTPQ:shared_process": [],
    "2C28DETC2:shared_process": [],
    "2C24RZY6N:shared_process": [],
    "2BZ5WHQHY:shared_process": [],
    "2C2XP7J9D:shared_process": [],
    "2C1TJ69QM:shared_process": [],
    "2BZCDVXQG:shared_process": [],
    "2C16E3V6Y:shared_process": [],
    "2C31ZM3HN:shared_process": [],
    "2BYP3Q9VB:shared_process": [],
    "2BZRZ4XD8:shared_process": [],
    "2C28U48M2:shared_process": [],
    "2BZ76V9TV:shared_process": [],
    "2C2YR1C92:shared_process": [],
    "2C3BAXZXW:shared_process": [],
    "2C2DMU7N5:shared_process": [],
    "2C2ZY9GQ2:shared_process": [],
    "2BZ896HDX:shared_process": [],
    "2BZZY31R4:shared_process": []
  },
  "config": {},
  "info": {}
}